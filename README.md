# TensorFlow.js ã§ã€Œã‚¢ã‚·ã‚¢ãƒ«ã€ã‚’éŸ³å£°æ¤œçŸ¥ã•ã›ã‚‹

TensorFlow.js ã‚’ä½¿ã£ã¦ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ **ã€Œã‚¢ã‚·ã‚¢ãƒ«ï¼ˆasialï¼‰ã€** ã‚’å«ã‚€çŸ­éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã‚’**ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§åˆ†é¡**ã§ãã‚‹ã‹æ¤œè¨¼ã—ã¾ã—ãŸã€‚  
å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆæ‰‹é †ã¨ã€Webã‚¢ãƒ—ãƒªã§ã®æ¨è«–å®Ÿè£…ï¼ˆãƒã‚¤ã‚¯å…¥åŠ›â†’MFCCâ†’predictï¼‰ã¾ã§ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚

ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ä¸€å¼ã¯ã“ã¡ã‚‰ã®ãƒªãƒã‚¸ãƒˆãƒªã§å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚  
https://github.com/ytatsuno/202601_voice_recognition


## 1. TensorFlow.js ã¨ã¯

TensorFlow.js ã¯ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‚„ Node.js ä¸Šã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®**å­¦ç¿’ãƒ»æ¨è«–**ãŒã§ãã‚‹ JavaScript å‘ã‘ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚  
å†…éƒ¨ã§ã¯ **Tensorï¼ˆãƒ†ãƒ³ã‚½ãƒ«ï¼‰** ã¨ã„ã†å¤šæ¬¡å…ƒé…åˆ—ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ä½¿ã„ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã®ã‚„ã‚Šå–ã‚Šã‚’è¡Œã„ã¾ã™ã€‚  
ãã®ãŸã‚ã€Webã‚µã‚¤ãƒˆã‚„ IoT ãƒ‡ãƒã‚¤ã‚¹ãªã©ã§ã‚‚ã€ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’æ¯”è¼ƒçš„æ‰‹è»½ã«çµ„ã¿è¾¼ã‚ã¾ã™ã€‚


## 2. ã€Œã‚¢ã‚·ã‚¢ãƒ«ã€ã‚’èªè­˜ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ

ä»Šå›ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ä»¥ä¸‹ã®ã‚¯ãƒ©ã‚¹ã‚’åˆ†é¡ã—ã¾ã™ã€‚

```
- æŒ‡ç¤ºã‚³ãƒãƒ³ãƒ‰ï¼š`up, down, left, right, go, stop`  
- è‡ªä½œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼š`asial`  
- è¿½åŠ ã‚¯ãƒ©ã‚¹ï¼š`unknown`, `background_noise`
```
æŒ‡ç¤ºã‚³ãƒãƒ³ãƒ‰ï¼ˆçŸ­æ™‚é–“éŸ³å£°ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã¯ã€Google ãŒæä¾›ã—ã¦ã„ã‚‹ Speech Commands ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã—ã¾ã—ãŸã€‚  
[Speech Commands v0.02](https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz)

### 2-1. éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’é›†ã‚ã‚‹

<img src="https://raw.githubusercontent.com/ytatsuno/202601_voice_recognition/main/res/step3.png" alt="">


MacBookAir ã®ã€Œãƒœã‚¤ã‚¹ãƒ¡ãƒ¢ã€ã§ `asial` ã®éŸ³å£°ã‚’åéŒ²ã—ã¾ã™ã€‚

1. ã€Œãƒœã‚¤ã‚¹ãƒ¡ãƒ¢ã€ã‚’é–‹ã  
2. èµ¤ã„éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™  
3. 0.5ç§’å¾…ã£ã¦ã‹ã‚‰ã€Œã‚¢ã‚·ã‚¢ãƒ«ã€ã¨1å›ç™ºè©±  
4. 0.5ç§’å¾…ã£ã¦åœæ­¢  
5. ã‚¿ã‚¤ãƒˆãƒ«ã‚’åˆ†ã‹ã‚‹ã‚ˆã†ã«å¤‰æ›´  
   - ä¾‹ï¼š`asial_yao_001`ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰_è©±è€…å_é€£ç•ªï¼‰

ç›®å®‰ã¨ã—ã¦ **1äººã‚ãŸã‚Š 100ã€œ300 ä»¶**ç”¨æ„ã—ã¾ã™ã€‚  
ï¼ˆä»Šå›ã¯æ¤œè¨¼ã®ãŸã‚ã€1äººåˆ†ã®ã¿ä½œæˆã—ã¾ã—ãŸï¼‰

### 2-2. éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’æˆå½¢ã™ã‚‹

Speech Commands ç³»ã®çŸ­éŸ³å£°é‹ç”¨ã«åˆã‚ã›ã‚‹ãŸã‚ã€`ffmpeg` ã§éŸ³å£°ã®å½¢å¼ãƒ»é•·ã•ã‚’æƒãˆã¾ã™ã€‚


```
å½¢å¼ï¼šWAV
ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ï¼šPCMï¼ˆéåœ§ç¸®ï¼‰
ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆï¼š16,000 Hz
ãƒãƒ£ãƒ³ãƒãƒ«ï¼š1ï¼ˆmonoï¼‰
ãƒ“ãƒƒãƒˆæ·±åº¦ï¼š16-bitï¼ˆpcm_s16leï¼‰
é•·ã•ï¼š1.0ç§’ï¼ˆspeech-commandsç³»ã®çŸ­éŸ³ã‚³ãƒãƒ³ãƒ‰é‹ç”¨ã«åˆã‚ã›ã‚„ã™ã„ï¼‰
```

ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã€ffmpeg ã‚’åˆ©ç”¨ã—ã¦ `dataset` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® m4a ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ wav ã«å¤‰æ›ã—ã¾ã—ãŸã€‚

```sh
# m4a => wav å¤‰æ›
ffmpeg -i input.m4a -ac 1 -ar 16000 -c:a pcm_s16le input.wav
# é–‹å§‹ã‹ã‚‰0.5ç§’å¾Œã‹ã‚‰ã€é•·ã•ï¼š1.0ç§’é–“ã® wav ã«å¤‰æ›
ffmpeg -i input.wav -ss 0.5 -t 1.0 -ac 1 -ar 16000 -c:a pcm_s16le cut.wav
```

### 2-3. éŸ³å£°è§£æãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ

ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¯ Google Colab ã§è¡Œã„ã¾ã—ãŸã€‚
ä½¿ç”¨ã—ãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼ˆipynbï¼‰ã¯ã“ã¡ã‚‰ã§ã™ã€‚
[ipynbã®ãƒªãƒ³ã‚¯](https://github.com/ytatsuno/202601_voice_recognition/blob/main/asial_kws_colab_tfjs_udlrgo_stop_asial_pcm16_1768353193.ipynb)

å‡¦ç†ã®æµã‚Œã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚
1. Speech Commands ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰  
   - æ—¢å­˜ã®æŒ‡ç¤ºã‚³ãƒãƒ³ãƒ‰ï¼ˆ`up, down, left, right, go, stop`ï¼‰ã¨ `unknown` ç”¨ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ©ç”¨  
2. `_background_noise_` ã‹ã‚‰ 1 ç§’ã®ãƒã‚¤ã‚ºç‰‡ã‚’ä½œã‚Šã€å­¦ç¿’æ™‚ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒŸãƒƒã‚¯ã‚¹  
3. è‡ªä½œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ `asial` ã®éŸ³å£°ã‚’ Google Driveï¼ˆMy Driveï¼‰ã‹ã‚‰èª­ã¿è¾¼ã¿  
4. å‰å‡¦ç†ï¼ˆç‰¹å¾´é‡å¤‰æ›ï¼‰ã‚’å®Ÿè¡Œ  
    1. æ“ä½œèªã®éŸ³å£°WAVï¼ˆasialã‚‚å«ã‚€ï¼‰ ã‚’ **16kHz / mono / 1.0ç§’ / float32** ã«çµ±ä¸€ï¼ˆé‡è¦ï¼‰
    1. æ³¢å½¢ï¼ˆæ™‚é–“é ˜åŸŸï¼‰: Float32Array => Tensor1DåŒ–
    2. Tensor1DåŒ–ã—ãŸæ³¢å½¢ => çŸ­æ™‚é–“ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ï¼ˆè¤‡ç´ æ•°ï¼‰
    3. æ³¢å½¢ã®è¤‡ç´ ã‚¹ãƒšã‚¯ãƒˆãƒ« => ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼ˆæŒ¯å¹…ï¼ˆmagnitudeï¼‰ã‚’åˆ©ç”¨ï¼‰ã¸å¤‰æ›
    4. ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ  => æ³¢å½¢ã®ãƒ¡ãƒ«å°ºåº¦ï¼ˆéŸ³ã®é«˜ä½ã®å°ºåº¦ï¼‰ ã‚’è¨ˆç®—
    5. æ³¢å½¢ã®ãƒ¡ãƒ«å°ºåº¦ => MFCCï¼ˆãƒ¡ãƒ«å‘¨æ³¢æ•°ã‚±ãƒ—ã‚¹ãƒˆãƒ©ãƒ ä¿‚æ•°[1, T, 13, 1] ï¼‰ã®ã¾ã¨ã¾ã‚Šã«å¤‰æ›
5. æˆå½¢ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ CNNï¼ˆç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã‚’å­¦ç¿’  
6. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ TFJS å‘ã‘ã«å¤‰æ›ã— `model.json` ã‚’å‡ºåŠ›  

## 3. ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶å´ï¼‰éŸ³å£°æ¨è«–å‡¦ç†ã®å®Ÿè£…

ãƒ–ãƒ©ã‚¦ã‚¶ã§ AudioContext ã‹ã‚‰å–å¾—ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ¨è«–ã—ã¾ã™ã€‚
æ¨è«–ã®ãŸã‚ã€å­¦ç¿’æ¸ˆã¿ model ãŒèª­ã¿è¾¼ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ã‚‹é•·ã•ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ¯ã®ç‰¹å¾´é‡æ•°ã‚’å«ã‚€MFCCï¼ˆãƒ¡ãƒ«å‘¨æ³¢æ•°ã‚±ãƒ—ã‚¹ãƒˆãƒ©ãƒ ä¿‚æ•°[1, T, 13, 1]ï¼‰ã®ã¾ã¨ã¾ã‚Šï¼‰ã«å¤‰æ›ã—ã¾ã™ã€‚
æ¨è«–ã¾ã§ã®æµã‚Œã¯ä»¥ä¸‹ã§ã™ã€‚

1. `AudioContext` ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ `Float32Array`ï¼ˆ1æ¬¡å…ƒé…åˆ—ï¼‰ã¨ã—ã¦å–å¾—  
2. å–å¾—ã—ãŸæ³¢å½¢ã‚’ã€ãƒ¢ãƒ‡ãƒ«å…¥åŠ›å½¢å¼ï¼ˆMFCCï¼‰ã¸å¤‰æ›  
    1. æ³¢å½¢ï¼ˆæ™‚é–“é ˜åŸŸï¼‰: Float32Array => Tensor1DåŒ–
    2. Tensor1DåŒ–ã—ãŸæ³¢å½¢ => çŸ­æ™‚é–“ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ï¼ˆè¤‡ç´ æ•°ï¼‰
    3. æ³¢å½¢ã®è¤‡ç´ ã‚¹ãƒšã‚¯ãƒˆãƒ« => ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼ˆæŒ¯å¹…ï¼ˆmagnitudeï¼‰ã‚’åˆ©ç”¨ï¼‰ã¸å¤‰æ›
    4. ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ  => æ³¢å½¢ã®ãƒ¡ãƒ«å°ºåº¦ï¼ˆéŸ³ã®é«˜ä½ã®å°ºåº¦ï¼‰ ã‚’è¨ˆç®—
    5. æ³¢å½¢ã®ãƒ¡ãƒ«å°ºåº¦ => MFCCï¼ˆãƒ¡ãƒ«å‘¨æ³¢æ•°ã‚±ãƒ—ã‚¹ãƒˆãƒ©ãƒ ä¿‚æ•°[1, T, 13, 1] ï¼‰ã®ã¾ã¨ã¾ã‚Šã«å¤‰æ›
3. 1ç§’åˆ†ã®MFCCã®ã¾ã¨ã¾ã‚Šã«ã¤ã„ã¦ã€model.predict ã‚’å®Ÿè¡Œ

å®Ÿè£…ã¯ä»¥ä¸‹ã®é€šã‚Šã¨ãªã‚Šã¾ã™ã€‚

`www/js/asialVoiceRecognition.js`

```js

// ------------- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° -------------
let model, labels;

// ------------- éŸ³å£°ã®åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ -------------
// ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ã€Œ16kHz / 1ç§’ã€ã®å›ºå®šé•·ã‚¯ãƒªãƒƒãƒ—ã‚’å‰æã«ã—ã¦ã„ã¾ã™ã€‚
const SR = 16000;               // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•° (Hz)
const CLIP_SECONDS = 1.0;       // 1å›ã®æ¨è«–ã«ä½¿ã†é•·ã•ï¼ˆç§’ï¼‰
const CLIP_SAMPLES = SR * CLIP_SECONDS; // 1ç§’ã¶ã‚“ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆ=16000ï¼‰

// ------------- ç‰¹å¾´é‡ï¼ˆSTFT / Mel / MFCCï¼‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ -------------
// â˜…ã“ã“ã¯å­¦ç¿’æ™‚ã¨ä¸€è‡´ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ˆçª“é•·/ã‚¹ãƒ†ãƒƒãƒ—/FFTé•·ãŒé•ã†ã¨æ¬¡å…ƒã‚„åˆ†å¸ƒãŒã‚ºãƒ¬ã‚‹ï¼‰
const frameLength = 640; // 40ms (= 16000Hz * 0.04s)
const frameStep   = 320; // 20ms (= 16000Hz * 0.02s)
const fftLength   = 1024;

// Melãƒ•ã‚£ãƒ«ã‚¿ãƒãƒ³ã‚¯ã®æ•°ã¨ã€æœ€çµ‚çš„ã«ä½¿ã†MFCCä¿‚æ•°æ•°
const numMelBins  = 40;
const numMfcc     = 13;

// Melãƒ•ã‚£ãƒ«ã‚¿ã®å‘¨æ³¢æ•°ãƒ¬ãƒ³ã‚¸
const lowerEdgeHz = 20.0;
const upperEdgeHz = SR / 2; // ãƒŠã‚¤ã‚­ã‚¹ãƒˆå‘¨æ³¢æ•°ï¼ˆ= 8000Hzï¼‰

// STFTã®å‡ºåŠ›ï¼ˆrfftï¼‰ã®å‘¨æ³¢æ•°binæ•°
// rfftã®ãƒ¦ãƒ‹ãƒ¼ã‚¯binæ•° = fftLength/2 + 1
const numSpectrogramBins = fftLength / 2 + 1;

// ------------- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ¯ãƒ•ãƒ¬ãƒ¼ãƒ ä½œã‚‰ãªã„ï¼‰ -------------
// Melé‡ã¿è¡Œåˆ—ã¨DCTè¡Œåˆ—ã¯æ¯å›ä½œã‚‹ã¨é‡ã„ã®ã§ã€åˆå›ã ã‘ä½œã£ã¦ä¿æŒã—ã¾ã™ã€‚
let melW = null;   // shape: [numSpectrogramBins, numMelBins]
let dctM = null;   // shape: [numMelBins, numMfcc]

// ------------- Hz <-> Mel å¤‰æ› -------------
function hzToMel(hz) {
  return 2595 * Math.log10(1 + hz / 700);
}
function melToHz(mel) {
  return 700 * (Math.pow(10, mel / 2595) - 1);
}

// ------------- Melãƒ•ã‚£ãƒ«ã‚¿ãƒãƒ³ã‚¯é‡ã¿è¡Œåˆ—ã‚’ç”Ÿæˆ -------------
// ç›®çš„ï¼š
//   |spectrogram| (T x numSpectrogramBins) ã«æ›ã‘ã‚‹ã“ã¨ã§
//   mel (T x numMelBins) ã‚’å¾—ã‚‹ãŸã‚ã®é‡ã¿è¡Œåˆ—ã‚’ä½œã‚‹
//
// è¿”ã‚Šå€¤ï¼š
//   shape [numSpectrogramBins, numMelBins]
//   â€»ã‚ã¨ã§ spectrogram.matMul(melW) ã™ã‚‹æƒ³å®š
function buildMelWeightMatrix(numMelBins, numSpectrogramBins, sampleRate, lowerEdgeHz, upperEdgeHz) {
  // numSpectrogramBins = fftLength/2 + 1 ãªã®ã§ã€fftLength ã¯ (numSpectrogramBins - 1) * 2 ã§æˆ»ã›ã‚‹
  const fftLen = (numSpectrogramBins - 1) * 2;

  // å‘¨æ³¢æ•°ãƒ¬ãƒ³ã‚¸ã‚’Melã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ›
  const lowerMel = hzToMel(lowerEdgeHz);
  const upperMel = hzToMel(upperEdgeHz);

  // Melä¸Šã§ç­‰é–“éš”ãªã€Œä¸‰è§’ãƒ•ã‚£ãƒ«ã‚¿ã€ã®ä¸­å¿ƒç‚¹ï¼ˆ+ä¸¡ç«¯ï¼‰ã‚’ä½œã‚‹
  // ä¸‰è§’ãƒ•ã‚£ãƒ«ã‚¿ã¯ numMelBins å€‹å¿…è¦ãªã®ã§ã€å¢ƒç•Œã‚‚å«ã‚ã¦ numMelBins+2 ç‚¹
  const melPoints = new Array(numMelBins + 2);
  for (let i = 0; i < melPoints.length; i++) {
    melPoints[i] = lowerMel + (upperMel - lowerMel) * (i / (numMelBins + 1));
  }

  // Melç‚¹ã‚’Hzã«æˆ»ã™
  const hzPoints = melPoints.map(melToHz);

  // Hz -> FFT bin index ã¸å¤‰æ›
  // (fftLen+1) ã‚’æ›ã‘ã¦ã„ã‚‹ã®ã¯å®Ÿè£…ä¸Šã®ä¸€èˆ¬çš„ãªæ›ç®—ï¼ˆå­¦ç¿’å®Ÿè£…ã«åˆã‚ã›ã‚‹ã®ãŒå¤§äº‹ï¼‰
  const bin = hzPoints.map(hz => Math.floor((fftLen + 1) * hz / sampleRate));

  // é‡ã¿è¡Œåˆ—æœ¬ä½“ï¼ˆ2Dã‚’1Dã«è©°ã‚ã¦æœ€å¾Œã«tensor2dåŒ–ï¼‰
  // shape: [numSpectrogramBins, numMelBins]
  const data = new Float32Array(numSpectrogramBins * numMelBins);

  // mç•ªç›®ã®ä¸‰è§’ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆm=1..numMelBinsï¼‰ã‚’ä½œã‚‹
  for (let m = 1; m <= numMelBins; m++) {
    // ä¸‰è§’ã®å·¦ç«¯/ä¸­å¿ƒ/å³ç«¯ï¼ˆFFT binï¼‰
    const f0 = bin[m - 1];
    const f1 = bin[m];
    const f2 = bin[m + 1];

    // ä¸Šã‚Šéƒ¨åˆ†ï¼šf0 -> f1 ã§ 0 -> 1
    for (let k = f0; k < f1; k++) {
      if (k >= 0 && k < numSpectrogramBins && f1 !== f0) {
        const w = (k - f0) / (f1 - f0);
        data[k * numMelBins + (m - 1)] = w;
      }
    }

    // ä¸‹ã‚Šéƒ¨åˆ†ï¼šf1 -> f2 ã§ 1 -> 0
    for (let k = f1; k < f2; k++) {
      if (k >= 0 && k < numSpectrogramBins && f2 !== f1) {
        const w = (f2 - k) / (f2 - f1);
        data[k * numMelBins + (m - 1)] = Math.max(0, w);
      }
    }
  }

  return tf.tensor2d(data, [numSpectrogramBins, numMelBins], 'float32');
}

// ------------- DCT-IIï¼ˆç›´äº¤æ­£è¦åŒ–ï¼‰è¡Œåˆ—ã‚’ç”Ÿæˆ -------------
// ç›®çš„ï¼š
//   log-mel (T x numMelBins) ã«æ›ã‘ã¦ MFCC (T x numMfcc) ã‚’å¾—ã‚‹
//
// è¿”ã‚Šå€¤ï¼š
//   shape [numMelBins, numMfcc]
function buildDctMatrix(numMelBins, numMfcc) {
  const data = new Float32Array(numMelBins * numMfcc);

  // k=0 ã¨ãã‚Œä»¥å¤–ã§ã‚¹ã‚±ãƒ¼ãƒ«ãŒé•ã†ï¼ˆç›´äº¤æ­£è¦åŒ–ï¼‰
  const scale0 = 1 / Math.sqrt(numMelBins);
  const scale  = Math.sqrt(2 / numMelBins);

  // n: mel bin index, k: mfcc index
  for (let k = 0; k < numMfcc; k++) {
    for (let n = 0; n < numMelBins; n++) {
      const basis = Math.cos(Math.PI / numMelBins * (n + 0.5) * k);
      data[n * numMfcc + k] = (k === 0 ? scale0 : scale) * basis;
    }
  }
  return tf.tensor2d(data, [numMelBins, numMfcc], 'float32');
}

// ------------- ç‰¹å¾´é‡å¤‰æ›ç”¨è¡Œåˆ—ã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ -------------
function ensureFeatureMatrices() {
  if (!melW) melW = buildMelWeightMatrix(numMelBins, numSpectrogramBins, SR, lowerEdgeHz, upperEdgeHz);
  if (!dctM) dctM = buildDctMatrix(numMelBins, numMfcc);
}

// -----------------------------------------------------------------------------
// éŸ³å£°ã‚¯ãƒªãƒƒãƒ—ï¼ˆ1ç§’, 16kHzæƒ³å®šï¼‰ã‚’ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ç”¨ã®MFCCãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã™ã‚‹
//
// å…¥åŠ›:
//   audio1d: Float32Array ãªã©ã®1æ¬¡å…ƒé…åˆ—
//            é•·ã•ã¯ CLIP_SAMPLES (= SR * CLIP_SECONDS) ã‚’æƒ³å®š
//
// å‡ºåŠ›:
//   tf.Tensor, shape: [1, T, numMfcc(=13), 1]
//     - å…ˆé ­ã® 1 : ãƒãƒƒãƒæ¬¡å…ƒï¼ˆ1ã‚¯ãƒªãƒƒãƒ—åˆ†ï¼‰
//     - T        : æ™‚é–“ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆframeLength / frameStep / å…¥åŠ›é•·ã§æ±ºã¾ã‚‹ï¼‰
//     - 13       : MFCC æ¬¡å…ƒï¼ˆå„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ç‰¹å¾´é‡æ•°ï¼‰
//     - æœ€å¾Œã® 1 : ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒï¼ˆCNNç­‰ã€Œç”»åƒæ‰±ã„ã€ã®å…¥åŠ›å½¢çŠ¶ã«åˆã‚ã›ã‚‹ãŸã‚ï¼‰
//
// å‡¦ç†ã®æµã‚Œ:
//   wav(æ³¢å½¢) â†’ STFT(è¤‡ç´ ã‚¹ãƒšã‚¯ãƒˆãƒ«) â†’ |.|(æŒ¯å¹…ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ )
//          â†’ Melãƒ•ã‚£ãƒ«ã‚¿ãƒãƒ³ã‚¯ â†’ log â†’ DCT â†’ MFCC
//
// ãƒ¡ãƒ¢ãƒª:
//   tf.tidy() ã«ã‚ˆã‚Šã€ã“ã®é–¢æ•°å†…ã§ç”Ÿæˆã—ãŸä¸­é–“Tensorã¯è‡ªå‹•çš„ã«ç ´æ£„ã•ã‚Œã‚‹
//   ï¼ˆreturn ã™ã‚‹ MFCC ãƒ†ãƒ³ã‚½ãƒ«ã ã‘ãŒ tidy ã®å¤–ã«æ®‹ã‚‹ï¼‰
// -----------------------------------------------------------------------------
function audioToMfcc(audio1d) {
  // Melé‡ã¿è¡Œåˆ—(melW)ã¨DCTè¡Œåˆ—(dctM)ã‚’æœªä½œæˆãªã‚‰ç”Ÿæˆã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹
  ensureFeatureMatrices();

  return tf.tidy(() => {
    // 1) æ³¢å½¢ï¼ˆæ™‚é–“é ˜åŸŸï¼‰: JSé…åˆ—/TypedArray -> Tensor1D ã¸
    const wav = tf.tensor1d(audio1d);

    // 2) STFT: çŸ­æ™‚é–“ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ï¼ˆè¤‡ç´ æ•°ï¼‰
    //    shape: [T, numSpectrogramBins]ï¼ˆnumSpectrogramBins = fftLength/2 + 1ï¼‰
    const stft = tf.signal.stft(wav, frameLength, frameStep, fftLength);

    // 3) è¤‡ç´ ã‚¹ãƒšã‚¯ãƒˆãƒ« -> ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¸
    //    ã“ã“ã§ã¯æŒ¯å¹…ï¼ˆmagnitudeï¼‰= abs ã‚’æ¡ç”¨
    //    â€»å­¦ç¿’æ™‚ãŒã€Œãƒ‘ãƒ¯ãƒ¼ï¼ˆmagnitude^2ï¼‰ã€ãªã‚‰ square() ç­‰ã«åˆã‚ã›ã‚‹å¿…è¦ã‚ã‚Š
    const spectrogram = tf.abs(stft); // shape: [T, numSpectrogramBins]

    // 4) Melãƒ•ã‚£ãƒ«ã‚¿ãƒãƒ³ã‚¯é©ç”¨: å‘¨æ³¢æ•°bin -> Melå¸¯åŸŸã¸é›†ç´„
    //    (T x bins) @ (bins x mel) => (T x mel)
    const mel = spectrogram.matMul(melW); // shape: [T, numMelBins]

    // 5) log-Mel: å¼·åº¦ã‚’å¯¾æ•°åœ§ç¸®ï¼ˆ0å›é¿ã®ãŸã‚å¾®å°å€¤ã‚’åŠ ç®—ï¼‰
    const logMel = tf.log(mel.add(1e-6)); // shape: [T, numMelBins]

    // 6) DCTã§MFCCã¸: (T x mel) @ (mel x mfcc) => (T x mfcc)
    //    Melå¸¯åŸŸã®æƒ…å ±ã‚’å°‘æ•°æ¬¡å…ƒï¼ˆã“ã“ã§ã¯13ï¼‰ã«åœ§ç¸®ã—ã€éŸ³å£°è­˜åˆ¥ã«ä½¿ã„ã‚„ã™ãã™ã‚‹
    const mfcc = logMel.matMul(dctM); // shape: [T, numMfcc]

    // 7) ãƒ¢ãƒ‡ãƒ«å…¥åŠ›å½¢çŠ¶ã«åˆã‚ã›ã¦æ¬¡å…ƒè¿½åŠ 
    //    [T, 13] -> [T, 13, 1] -> [1, T, 13, 1]
    return mfcc.expandDims(-1).expandDims(0);
  });
}

// ------------- ãƒ¢ãƒ‡ãƒ«ã¨ãƒ©ãƒ™ãƒ«ã®èª­ã¿è¾¼ã¿ -------------
async function loadAssets() {
  // ä¾‹: ./tfjs_model_tfonly/model.json ã¨ ./tfjs_model_tfonly/labels.json ãŒã‚ã‚‹æƒ³å®š
  // model.json ã¯ tfjs-converter ãªã©ã§å‡ºåŠ›ã•ã‚ŒãŸKerasäº’æ›ã®ãƒ¢ãƒ‡ãƒ«
  model = await tf.loadLayersModel("./tfjs_model/model.json");

  // labels.json ã¯ { "labels": ["silence", "yes", ...] } ã®ã‚ˆã†ãªå½¢å¼ã‚’æƒ³å®š
  labels = await (await fetch("./tfjs_model/labels.json")).json();

  // ãƒ©ãƒ™ãƒ«ä¸€è¦§ã‚’ç”»é¢ã«è¡¨ç¤º
  document.querySelector("#words").textContent = labels.labels.join(", ");
}

// ------------- ãƒã‚¤ã‚¯å…¥åŠ›ã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦æ¨è«–ã™ã‚‹ -------------
async function startMicLoop(onaudioprocessCallback) {
  // ãƒã‚¤ã‚¯è¨±å¯ã‚’å–ã‚Šã€éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

  // AudioContext ã‚’ 16kHz æŒ‡å®šã§ç”Ÿæˆï¼ˆç’°å¢ƒã«ã‚ˆã‚Šå³å¯†ã«16kHzã«ãªã‚‰ãªã„å ´åˆã‚‚ã‚ã‚Šã¾ã™ï¼‰
  const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SR });

  // MediaStream -> AudioNode
  const source = audioCtx.createMediaStreamSource(stream);

  // ScriptProcessorNodeï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼APIï¼‰
  // 4096ã‚µãƒ³ãƒ—ãƒ«å˜ä½ã§ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒæ¥ã‚‹ï¼ˆ16kHzãªã‚‰ç´„256msã”ã¨ï¼‰
  // â€»æœ¬æ ¼é‹ç”¨ãªã‚‰ AudioWorklet ãŒæ¨å¥¨ã§ã™ãŒã€æœ€å°æ§‹æˆã¨ã—ã¦ScriptProcessorã‚’ä½¿ç”¨
  const processor = audioCtx.createScriptProcessor(4096, 1, 1);

  // ã“ã“ã«å…¥åŠ›éŸ³å£°ã‚’æºœã‚ã¦ã„ãï¼ˆå¯å¤‰é•·ï¼‰
  let buffer = new Float32Array(0);
  let running = true;

  // éŸ³å£°ãŒæ¥ã‚‹ãŸã³ã«å‘¼ã°ã‚Œã‚‹
  processor.onaudioprocess = async (e) => {
    // ãƒ¢ãƒãƒ©ãƒ«1chæƒ³å®šã§0ç•ªã‚’å–ã‚‹
    const input = e.inputBuffer.getChannelData(0);

    // æ—¢å­˜bufferã®æœ«å°¾ã« input ã‚’é€£çµ
    const tmp = new Float32Array(buffer.length + input.length);
    tmp.set(buffer, 0);
    tmp.set(input, buffer.length);
    buffer = tmp;

    // 1ç§’åˆ†ãŸã¾ã£ãŸã‚‰æ¨è«–
    // ï¼ˆé‡ã„å ´åˆã¯ã€æ¨è«–é–“éš”ã‚’é•·ãã™ã‚‹/ã‚­ãƒ¥ãƒ¼åŒ–/éåŒæœŸåˆ¶å¾¡ãªã©ã‚’æ¤œè¨ï¼‰
    if (buffer.length >= CLIP_SAMPLES) {
      // å…ˆé ­ã‹ã‚‰1ç§’ã‚’åˆ‡ã‚Šå‡ºã—
      const clip = buffer.slice(0, CLIP_SAMPLES);

      // æ¬¡å›ã«å‘ã‘ã¦åŠåˆ†(0.5ç§’)ã ã‘æ®‹ã—ã¦æ¨ã¦ã‚‹ = 0.5ç§’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
      buffer = buffer.slice(Math.floor(CLIP_SAMPLES / 2));

      // ç‰¹å¾´é‡åŒ–ã—ã¦ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã¸
      const x = audioToMfcc(clip);

      // æ¨è«–
      // model.predict ã¯é€šå¸¸ Tensor ã‚’è¿”ã™ï¼ˆåˆ†é¡ãªã‚‰ shape [1, numLabels] ç­‰ï¼‰
      const y = model.predict(x);

      // Tensor -> JSé…åˆ—ã¸ï¼ˆGPU/wasmâ†’CPUã¸è»¢é€ãŒç™ºç”Ÿï¼‰
      const scores = await y.data();

      // tidyå¤–ã®Tensorãªã®ã§æ˜ç¤ºç ´æ£„
      x.dispose();
      y.dispose();

      if(onaudioprocessCallback && typeof onaudioprocessCallback === 'function') {
        onaudioprocessCallback(scores, labels);
      }
    }
  };

  // ãƒãƒ¼ãƒ‰æ¥ç¶š
  // source -> processor ã¸å…¥åŠ›ã‚’æµã—ã€
  // processor -> destination ã¸ç¹‹ãŒãªã„ã¨ScriptProcessorãŒå‹•ã‹ãªã„å®Ÿè£…ãŒå¤šã„ã§ã™
  source.connect(processor);
  processor.connect(audioCtx.destination);

  // åœæ­¢ç”¨ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ã‚’è¿”ã™
  return {
    stop: async () => {
      running = false;

      try { processor.disconnect(); } catch {}
      try { source.disconnect(); } catch {}

      try {
        stream.getTracks().forEach(t => t.stop());
      } catch {}

      try {
        await audioCtx.close();
      } catch {}
    }
  };
}
```

ã“ã¡ã‚‰ã®éŸ³å£°èªè­˜ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã—ã¦ä»¥ä¸‹ã®Webã‚¢ãƒ—ãƒªã‚’ä½œæˆã—ã¾ã—ãŸã€‚

```
- ç”»é¢å·¦ä¸Šã‹ã‚‰ç”»é¢é«˜ã•åºƒã•90%ã®éƒ¨åˆ†ã‚’åˆ©ç”¨ã™ã‚‹
- çµµæ–‡å­—ã€Œ:turtle:ã€ã‚’ç”»é¢ä¸­å¤®ã«æç”»
-ã€Œupã€ã€ã€Œdownã€ã€ã€Œleftã€ã€ã€Œrightã€ã‚’éŸ³å£°èªè­˜ã§èã“ãˆãŸã‚‰ã€ã€Œ:turtle:ã€ã®å‘ãã‚’å¤‰æ›´
-ã€Œgoã€ ã‚’éŸ³å£°èªè­˜ã§èã“ãˆãŸã‚‰ã€ã€Œ:turtle:ã€ã®ä½ç½®ã‚’å¤‰æ›´ï¼ˆå‘ã„ã¦ã„ã‚‹æ–¹å‘ã¸ + 1 ï¼‰
-ã€Œasialã€ãŒèã“ãˆãŸã‚‰ã€Œ:turtle:ã€ã®å¤§ãã•ã‚’40pxã«å¤‰æ›´ã—å…ƒã®å¤§ãã•ã«æˆ»ã™å¤‰æ›´
-ã€Œstopã€ ã‚’éŸ³å£°èªè­˜ã§èã“ãˆãŸã‚‰ã€ã€Œã‚¢ãƒ—ãƒªçµ‚äº†ã€ã‚’è¡¨ç¤ºã—ã¦ voiceRecognition ã‚‚æ­¢ã‚ã‚‹
```


`index.html`

```html
<html>
  <head>
    <meta charset="utf-8" />
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <style>
      html, body {
        margin: 0;
        padding: 0;
        height: 100%;
        background: #fefefe;  /* â˜…èƒŒæ™¯ */
        color: #111;
        font-family: system-ui, -apple-system, "Segoe UI", Roboto, "Noto Sans JP", sans-serif;
      }

      /* ç”»é¢å·¦ä¸Šã‹ã‚‰ 90% x 90% ã‚’ä½¿ã† */
      #stage {
        position: absolute;
        left: 0;
        top: 0;
        width: 90vw;
        height: 90vh;
        border: 1px solid rgba(0,0,0,0.15);
        box-sizing: border-box;
        overflow: hidden;
        background: #fefefe; /* â˜…èƒŒæ™¯ï¼ˆå¿µã®ãŸã‚ï¼‰ */
      }

      /* â˜…æç”»ã¯ canvas ã«å¯„ã›ã‚‹ */
      #gameCanvas {
        display: block;
        width: 100%;
        height: 100%;
      }

      #hud {
        position: absolute;
        left: 8px;
        bottom: 8px;
        font-size: 12px;
        opacity: 0.9;
        background: rgba(255,255,255,0.75);
        color: #111;
        padding: 6px 8px;
        border-radius: 8px;
        border: 1px solid rgba(0,0,0,0.08);
        backdrop-filter: blur(4px);
      }

      #endOverlay {
        position: absolute;
        inset: 0;
        display: none;
        align-items: center;
        justify-content: center;
        font-size: 32px;
        background: rgba(255,255,255,0.75);
        color: #111;
      }
    </style>
  </head>

  <body>
    <div id="stage">
      <canvas id="gameCanvas"></canvas>

      <div id="endOverlay">ã‚¢ãƒ—ãƒªçµ‚äº†</div>
      <div id="hud">
        <div>labels: <span id="words">(loading...)</span></div>
        <div>heard: <span id="heard">(none)</span></div>
      </div>
    </div>

    <script src="./js/asialVoiceRecognition.js"></script>
    <script>
      // ---------------- DOM ----------------
      const stage = document.getElementById("stage");
      const canvas = document.getElementById("gameCanvas");
      const ctx = canvas.getContext("2d");
      const endOverlay = document.getElementById("endOverlay");
      const heardEl = document.getElementById("heard");

      // HUDè¡¨ç¤ºã¯æ—¢å­˜ã®ã¾ã¾åˆ©ç”¨
      const wordsEl = document.getElementById("words");

      // ---------------- çŠ¶æ…‹ ----------------
      const BASE_SIZE_PX = 28;
      const ASIAL_SIZE_PX = 40;

      // ã€Œ+1ã€ã®å˜ä½ï¼ˆã‚°ãƒªãƒƒãƒ‰1ãƒã‚¹åˆ†ï¼‰
      const STEP_PX = 30;

      // æ–¹å‘ï¼ˆã‚ãªãŸã®æ‰‹å…ƒã§å‹•ã„ã¦ã„ã‚‹ rot ã‚’è¸è¥²ï¼‰
      // â€»rot ã¯ã€Œçµµæ–‡å­—ã®å‘ãã€ã‚’ canvas ã§å›è»¢ã—ã¦æããŸã‚ã«ä½¿ã†
      const DIRECTIONS = {
        up:    { dx:  0, dy: -1, rot:  90 },
        left:  { dx: -1, dy:  0, rot:   0 },
        down:  { dx:  0, dy:  1, rot: -90 },
        right: { dx:  1, dy:  0, rot: 180 },
      };

      let dir = "left";
      let gridX = 0;
      let gridY = 0;

      // é€£æ‰“é˜²æ­¢
      const COOLDOWN_MS = 700;
      let lastCmdAt = 0;

      // asial ãƒ‘ãƒ«ã‚¹
      let asialTimer = null;
      let turtleSizePx = BASE_SIZE_PX;

      // stop ã•ã‚ŒãŸã‹
      let ended = false;

      // startMicLoop ã® controller
      let micController = null;

      // â˜…è»Œè·¡ï¼ˆé€šã£ãŸåœ°ç‚¹ã‚’ä¿å­˜ï¼‰
      // ä¸­å¤®ã‚’ (0,0) ã¨ã™ã‚‹ã€Œã‚°ãƒªãƒƒãƒ‰åº§æ¨™ã€ã§ä¿å­˜ã—ã¦ã€æç”»æ™‚ã« px ã«å¤‰æ›
      const trail = [{ x: 0, y: 0 }];

      // ---------------- ä½ç½®å¤‰æ› ----------------
      function getStageSize() {
        return { w: stage.clientWidth, h: stage.clientHeight };
      }

      function gridToPx(gx, gy) {
        const { w, h } = getStageSize();
        const centerX = Math.floor(w / 2);
        const centerY = Math.floor(h / 2);
        return {
          x: centerX + gx * STEP_PX,
          y: centerY + gy * STEP_PX,
        };
      }

      // ---------------- canvas ãƒªã‚µã‚¤ã‚º ----------------
      function resizeCanvas() {
        // CSSã‚µã‚¤ã‚ºã¨å®Ÿãƒ”ã‚¯ã‚»ãƒ«ã‚’ä¸€è‡´ã•ã›ã‚‹ï¼ˆé«˜DPIå¯¾å¿œï¼‰
        const { w, h } = getStageSize();
        const dpr = window.devicePixelRatio || 1;
        canvas.width = Math.floor(w * dpr);
        canvas.height = Math.floor(h * dpr);
        canvas.style.width = w + "px";
        canvas.style.height = h + "px";
        ctx.setTransform(dpr, 0, 0, dpr, 0, 0);

        draw(); // ãƒªã‚µã‚¤ã‚ºæ™‚ã«å†æç”»
      }

      // ---------------- æç”» ----------------
      function clearBackground() {
        const { w, h } = getStageSize();
        ctx.clearRect(0, 0, w, h);
        ctx.fillStyle = "#fefefe";
        ctx.fillRect(0, 0, w, h);
      }

      function drawTrail() {
        if (trail.length < 2) return;

        ctx.save();
        ctx.lineWidth = 3;
        ctx.lineJoin = "round";
        ctx.lineCap = "round";
        ctx.strokeStyle = "rgba(20, 20, 20, 0.35)";

        ctx.beginPath();
        const p0 = gridToPx(trail[0].x, trail[0].y);
        ctx.moveTo(p0.x, p0.y);

        for (let i = 1; i < trail.length; i++) {
          const p = gridToPx(trail[i].x, trail[i].y);
          ctx.lineTo(p.x, p.y);
        }
        ctx.stroke();
        ctx.restore();

        // ç‚¹ã‚‚å°‘ã—å¼·èª¿ï¼ˆè¦‹ã‚„ã™ãï¼‰
        ctx.save();
        ctx.fillStyle = "rgba(20, 20, 20, 0.35)";
        for (const t of trail) {
          const p = gridToPx(t.x, t.y);
          ctx.beginPath();
          ctx.arc(p.x, p.y, 2.5, 0, Math.PI * 2);
          ctx.fill();
        }
        ctx.restore();
      }

      function drawTurtle() {
        const { w, h } = getStageSize();
        const margin = 20;

        let p = gridToPx(gridX, gridY);

        // ã‚¯ãƒ©ãƒ³ãƒ—ï¼ˆcanvas ç‰ˆã§ã‚‚åŒæ§˜ï¼‰
        p.x = Math.max(margin, Math.min(w - margin, p.x));
        p.y = Math.max(margin, Math.min(h - margin, p.y));

        ctx.save();
        ctx.translate(p.x, p.y);
        ctx.rotate((DIRECTIONS[dir].rot * Math.PI) / 180);

        ctx.font = `${turtleSizePx}px system-ui, "Apple Color Emoji", "Segoe UI Emoji", "Noto Color Emoji"`;
        ctx.textAlign = "center";
        ctx.textBaseline = "middle";
        ctx.fillStyle = "#111";
        ctx.fillText("ğŸ¢", 0, 0);

        ctx.restore();
      }

      function draw() {
        clearBackground();
        drawTrail();
        drawTurtle();
      }

      // ---------------- æ“ä½œ ----------------
      function setDirection(newDir) {
        if (!DIRECTIONS[newDir]) return;
        dir = newDir;
        draw();
      }

      function goForward() {
        gridX += DIRECTIONS[dir].dx;
        gridY += DIRECTIONS[dir].dy;

        // â˜…è»Œè·¡ã«è¿½åŠ ï¼ˆåŒã˜ç‚¹é€£ç¶šè¿½åŠ ã¯é¿ã‘ã‚‹ï¼‰
        const last = trail[trail.length - 1];
        if (!last || last.x !== gridX || last.y !== gridY) {
          trail.push({ x: gridX, y: gridY });
        }

        draw();
      }

      function asialPulse() {
        clearTimeout(asialTimer);
        turtleSizePx = ASIAL_SIZE_PX;
        draw();
        asialTimer = setTimeout(() => {
          turtleSizePx = BASE_SIZE_PX;
          draw();
        }, 350);
      }

      function endApp() {
        if (ended) return;
        ended = true;

        endOverlay.style.display = "flex";

        if (micController && typeof micController.stop === "function") {
          micController.stop();
        }
      }

      function shouldAcceptCommand(now) {
        if (ended) return false;
        if (now - lastCmdAt < COOLDOWN_MS) return false;
        lastCmdAt = now;
        return true;
      }

      // ---------------- ã‚¢ãƒ—ãƒªèµ·å‹• ----------------
      async function app() {
        // åˆæœŸæç”»
        turtleSizePx = BASE_SIZE_PX;
        resizeCanvas();

        await loadAssets();

        // labels ã‚’ HUD ã¸ï¼ˆasialVoiceRecognition.js å´ãŒæ—¢ã«æ›¸ã„ã¦ãã‚Œã‚‹ãªã‚‰ä¸è¦ã ãŒã€å¿µã®ãŸã‚ï¼‰
        if (wordsEl && window.labels && window.labels.labels) {
          wordsEl.textContent = window.labels.labels.join(", ");
        }

        micController = await startMicLoop((scores, labels) => {
          if (ended) return;

          // æ¨è«–çµæœã®ãƒ™ã‚¹ãƒˆã‚’æ¢ã™
          let bestIdx = 0;
          for (let i = 1; i < scores.length; i++) {
            if (scores[i] > scores[bestIdx]) bestIdx = i;
          }

          const bestWord = labels.labels[bestIdx];
          const bestScore = scores[bestIdx];

          heardEl.textContent = `${bestWord} (${bestScore.toFixed(3)})`;

          const THRESHOLD = 0.60;
          if (bestScore < THRESHOLD) return;

          const now = Date.now();

          if (bestWord === "stop") {
            endApp();
            return;
          }

          if (!shouldAcceptCommand(now)) return;

          if (bestWord === "up" || bestWord === "down" || bestWord === "left" || bestWord === "right") {
            setDirection(bestWord);
            return;
          }

          if (bestWord === "go") {
            goForward();
            return;
          }

          if (bestWord === "asial") {
            asialPulse();
            return;
          }
        });
      }

      window.addEventListener("resize", resizeCanvas);

      app();
    </script>
  </body>
</html>
```

å‹•ä½œã¯ä»¥ä¸‹ã®ã‚ˆã†ãªå‹•ãã¨ãªã‚Šã¾ã—ãŸã€‚

<img src="https://raw.githubusercontent.com/ytatsuno/202601_voice_recognition/main/res/step4.gif" alt="">


ã“ã‚Œã§Tensorflow.jsã‚’åˆ©ç”¨ã—ã¦ã€Œã‚¢ã‚·ã‚¢ãƒ«ã€ã‚„ã€Œgoã€ã€Œrightã€ãªã©ã®æ“ä½œèªã‚’éŸ³å£°èªè­˜ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚


## 4. æ„Ÿæƒ³

- ä»Šå›ã¯ 1 äººåˆ†ï¼ˆç´„ 100 ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã® `asial` éŸ³å£°ã ã‘ã§å­¦ç¿’ã—ãŸãŸã‚ã€è©±è€…ãŒå¤‰ã‚ã‚‹ã¨ç²¾åº¦ãŒè½ã¡ã‚„ã™ã„ã¨æ„Ÿã˜ã¾ã—ãŸã€‚  
  è¤‡æ•°äººã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã€æ±åŒ–æ€§èƒ½ã‚’ä¸Šã’ãŸã„ã§ã™ã€‚
- ä»Šå›ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€æ¨è«–å´ã§ã‚‚åŒã˜å‰å‡¦ç†ï¼ˆFloat32Array â†’ MFCCï¼‰ã‚’è¡Œãˆã°ã€ãƒ–ãƒ©ã‚¦ã‚¶ä»¥å¤–ï¼ˆã‚¢ãƒ—ãƒªï¼IoTãƒ‡ãƒã‚¤ã‚¹ç­‰ï¼‰ã§ã‚‚åŒæ§˜ã«å‹•ã‹ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚  
  æ¬¡ã¯åˆ¥ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¸ã®ç§»æ¤æ€§ã‚‚æ¤œè¨¼ã—ã¦ã¿ãŸã„ã§ã™ã€‚

## å‚è€ƒ

- How to Use Embedded Machine Learning to Do Speech Recognition on Arduino https://www.digikey.com/en/maker/projects/how-to-use-embedded-machine-learning-to-do-speech-recognition-on-arduino/1d5dd38c05d9494180d5e5b7b657804d
- Speech Commands Datasetï¼ˆGoogleï¼‰: https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz

