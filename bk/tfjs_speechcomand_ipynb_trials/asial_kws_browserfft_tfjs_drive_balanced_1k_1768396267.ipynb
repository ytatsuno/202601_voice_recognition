{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4fd7fc",
   "metadata": {},
   "source": [
    "# Speech Commands (BROWSER_FFT互換) カスタム学習 → TFJS(model.json + metadata.json)\n",
    "\n",
    "このノートは **@tensorflow-models/speech-commands の `BROWSER_FFT`** と整合するように、\n",
    "ブラウザ側の FFT スペクトログラム（WebAudio + AnalyserNode相当）を **Python側でも再現**して学習し、\n",
    "最後に **TFJS 形式の `model.json` + `metadata.json`** を出力します。\n",
    "\n",
    "対象ラベル（9クラス）:\n",
    "- up, down, left, right, go, stop, asial, unknown, background_noise\n",
    "\n",
    "> 重要: ここでは **44.1kHz / fftSize=1024 / 約1秒(43フレーム)** を前提にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3029c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 0) インストール（Colab向け：依存衝突を避ける版）\n",
    "!pip -q install -U pip\n",
    "\n",
    "# 学習に必要なもの\n",
    "!pip -q install \\\n",
    "  \"tensorflow==2.19.0\" \\\n",
    "  \"tensorflow-decision-forests==1.12.0\" \\\n",
    "  \"librosa==0.10.1\" \"soundfile==0.12.1\" \\\n",
    "  \"tqdm>=4.67\" \"scikit-learn>=1.6\"\n",
    "\n",
    "# TFJS 変換ツール（依存解決はしない）\n",
    "!pip -q install \"tensorflowjs==4.22.0\" --no-deps\n",
    "\n",
    "import sys, tensorflow as tf\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1) 設定（BROWSER_FFT互換パラメータ）\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "COMMAND_WORDS = [\"up\",\"down\",\"left\",\"right\",\"go\",\"stop\"]\n",
    "CUSTOM_WORD = \"asial\"\n",
    "LABELS = COMMAND_WORDS + [CUSTOM_WORD, \"unknown\", \"background_noise\"]\n",
    "\n",
    "# ---- BROWSER_FFT前提 ----\n",
    "SR = 44100\n",
    "FFT_SIZE = 1024\n",
    "FRAME_LEN = FFT_SIZE\n",
    "NUM_FRAMES = 43                 # floor(44100 / 1024) = 43\n",
    "CLIP_SAMPLES = NUM_FRAMES * FRAME_LEN  # 44032\n",
    "\n",
    "FULL_BINS = FFT_SIZE // 2       # 512（Nyquist除外相当）\n",
    "BINS = 232                      # 512で作ってもOK（重くなる）\n",
    "assert BINS <= FULL_BINS\n",
    "\n",
    "WORK = Path(\"/content/kws\")\n",
    "RAW  = WORK / \"raw\"\n",
    "STD  = WORK / \"std\"\n",
    "NOISE_POOL = WORK / \"noise_pool\"\n",
    "for p in [RAW, STD, NOISE_POOL]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"LABELS:\", LABELS)\n",
    "print(\"SR:\", SR, \"FFT_SIZE:\", FFT_SIZE, \"NUM_FRAMES:\", NUM_FRAMES, \"BINS:\", BINS)\n",
    "print(\"WORK:\", WORK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13ecb3",
   "metadata": {},
   "source": [
    "## 2) Speech Commands を取得して raw に配置\n",
    "- COMMAND_WORDS: up/down/left/right/go/stop\n",
    "- unknown: それ以外の単語からランダム抽出\n",
    "- background_noise: `_background_noise_` を 1秒にスライス（PCM16で保存）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cbd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2-1) Speech Commands v0.02 ダウンロード＆展開\n",
    "import tarfile, urllib.request\n",
    "\n",
    "speech_tar = WORK / \"speech_commands_v0.02.tar.gz\"\n",
    "speech_root = WORK / \"speech_commands_v0.02\"\n",
    "\n",
    "if not speech_root.exists():\n",
    "    if not speech_tar.exists():\n",
    "        url = \"https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\"\n",
    "        print(\"Downloading:\", url)\n",
    "        urllib.request.urlretrieve(url, speech_tar)\n",
    "    print(\"Extracting...\")\n",
    "    speech_root.mkdir(parents=True, exist_ok=True)\n",
    "    with tarfile.open(speech_tar, \"r:gz\") as tar:\n",
    "        tar.extractall(path=speech_root)\n",
    "\n",
    "print(\"speech_root:\", speech_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55da5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2-2) 指示コマンドを RAW にコピー\n",
    "import shutil\n",
    "\n",
    "def copy_all(src_dir: Path, dst_dir: Path):\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for f in src_dir.glob(\"*.wav\"):\n",
    "        shutil.copy2(f, dst_dir / f.name)\n",
    "    return len(list(dst_dir.glob(\"*.wav\")))\n",
    "\n",
    "for w in COMMAND_WORDS:\n",
    "    src = speech_root / w\n",
    "    if not src.exists():\n",
    "        print(\"WARN: missing word dir:\", src)\n",
    "        continue\n",
    "    n = copy_all(src, RAW / w)\n",
    "    print(w, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2-3) unknown を作る（Speech Commandsの他単語から抽出）\n",
    "import random, shutil\n",
    "\n",
    "target_unknown = sum(len(list((RAW / w).glob(\"*.wav\"))) for w in COMMAND_WORDS)\n",
    "exclude = set(COMMAND_WORDS + [CUSTOM_WORD, \"_background_noise_\", \"unknown\", \"background_noise\"])\n",
    "\n",
    "candidate_dirs = [p for p in speech_root.iterdir()\n",
    "                  if p.is_dir() and p.name not in exclude and not p.name.startswith(\".\")]\n",
    "\n",
    "cand_files = []\n",
    "for d in candidate_dirs:\n",
    "    cand_files.extend(list(d.glob(\"*.wav\")))\n",
    "\n",
    "random.shuffle(cand_files)\n",
    "cand_files = cand_files[:target_unknown]\n",
    "\n",
    "dst = RAW / \"unknown\"\n",
    "dst.mkdir(parents=True, exist_ok=True)\n",
    "for f in cand_files:\n",
    "    shutil.copy2(f, dst / f\"{f.parent.name}_{f.name}\")\n",
    "\n",
    "print(\"unknown:\", len(list(dst.glob(\"*.wav\"))), \"target:\", target_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f349330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2-4) background_noise 1秒片を生成（PCM16）\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "bg_src = speech_root / \"_background_noise_\"\n",
    "bg_dst = RAW / \"background_noise\"\n",
    "bg_dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def slice_noise_file(wav_path: Path, out_dir: Path, n_clips: int, prefix: str):\n",
    "    y, _ = librosa.load(str(wav_path), sr=SR, mono=True)\n",
    "    if len(y) < CLIP_SAMPLES:\n",
    "        return 0\n",
    "    count = 0\n",
    "    max_start = len(y) - CLIP_SAMPLES\n",
    "    for i in range(n_clips):\n",
    "        start = random.randint(0, max_start)\n",
    "        clip = y[start:start+CLIP_SAMPLES].astype(np.float32)\n",
    "        out = out_dir / f\"{prefix}_{wav_path.stem}_{i:04d}.wav\"\n",
    "        sf.write(out, clip, SR, subtype=\"PCM_16\")\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "CLIPS_PER_BG_FILE = 170  # 6本前後×170≈1000\n",
    "\n",
    "total = 0\n",
    "for f in tqdm(sorted(bg_src.glob(\"*.wav\"))):\n",
    "    total += slice_noise_file(f, bg_dst, CLIPS_PER_BG_FILE, prefix=\"bg\")\n",
    "\n",
    "# noise_pool にコピー（学習時ミックス用）\n",
    "if NOISE_POOL.exists():\n",
    "    shutil.rmtree(NOISE_POOL)\n",
    "NOISE_POOL.mkdir(parents=True, exist_ok=True)\n",
    "for f in bg_dst.glob(\"*.wav\"):\n",
    "    shutil.copy2(f, NOISE_POOL / f.name)\n",
    "\n",
    "print(\"background_noise clips:\", total)\n",
    "print(\"noise_pool clips:\", len(list(NOISE_POOL.glob(\"*.wav\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ce43a",
   "metadata": {},
   "source": [
    "## 3) asial データを RAW/asial に入れる\n",
    "- ZIPアップロード（wav入り）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9bff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3) asial をZIPアップロードで投入（任意）\n",
    "from google.colab import files\n",
    "import zipfile, shutil\n",
    "\n",
    "UPLOAD_ASIAL_ZIP = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if UPLOAD_ASIAL_ZIP:\n",
    "    uploaded = files.upload()\n",
    "    zip_path = next(iter(uploaded.keys()))\n",
    "    asial_dir = RAW / CUSTOM_WORD\n",
    "    asial_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        z.extractall(asial_dir)\n",
    "\n",
    "    # wav集約（サブフォルダにあってもOK）\n",
    "    wavs = list(asial_dir.rglob(\"*.wav\"))\n",
    "    for w in wavs:\n",
    "        if w.parent != asial_dir:\n",
    "            shutil.copy2(w, asial_dir / w.name)\n",
    "\n",
    "    print(\"asial wav count:\", len(list(asial_dir.glob(\"*.wav\"))))\n",
    "else:\n",
    "    print(\"Skip upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d57bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3-B) Google Drive からコピー（任意）\n",
    "USE_DRIVE = True  #@param {type:\"boolean\"}\n",
    "DRIVE_ASIAL_DIR = \"/content/drive/MyDrive/asial_wavs\"  #@param {type:\"string\"}\n",
    "\n",
    "if USE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    src = Path(DRIVE_ASIAL_DIR)\n",
    "    assert src.exists(), f\"not found: {src}\"\n",
    "    dst = RAW / CUSTOM_WORD\n",
    "    dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for f in src.glob(\"*.wav\"):\n",
    "        shutil.copy2(f, dst / f.name)\n",
    "    print(\"asial wav count:\", len(list(dst.glob('*.wav'))))\n",
    "else:\n",
    "    print(\"Skip drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b1023",
   "metadata": {},
   "source": [
    "## 4) WAV標準化（44.1kHz / mono / 約1秒 / PCM16）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ab59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4) 全ラベルの wav を STD に標準化（PCM16）\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import random\n",
    "MAX_STD_PER_LABEL = 1000  # 各クラスの最大件数（asial以外）\n",
    "\n",
    "\n",
    "def pad_or_trim(x, n):\n",
    "    if len(x) < n:\n",
    "        return np.pad(x, (0, n - len(x)))\n",
    "    return x[:n]\n",
    "\n",
    "def standardize_wav(in_path: Path, out_path: Path):\n",
    "    y, _ = librosa.load(str(in_path), sr=SR, mono=True)\n",
    "    y = pad_or_trim(y.astype(np.float32), CLIP_SAMPLES)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    sf.write(str(out_path), y, SR, subtype=\"PCM_16\")\n",
    "\n",
    "# STD を作り直す\n",
    "if STD.exists():\n",
    "    shutil.rmtree(STD)\n",
    "STD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for label in LABELS:\n",
    "    src_dir = RAW / label\n",
    "    if not src_dir.exists():\n",
    "        print(\"WARN missing label dir:\", src_dir)\n",
    "        continue\n",
    "    files = sorted(src_dir.glob(\"*.wav\"))\n",
    "    for f in tqdm(files, desc=f\"std:{label}\"):\n",
    "        standardize_wav(f, STD / label / f.name)\n",
    "\n",
    "print(\"=== STD counts ===\")\n",
    "for label in LABELS:\n",
    "    print(label, len(list((STD/label).glob(\"*.wav\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd4e9a",
   "metadata": {},
   "source": [
    "## 5) BROWSER_FFT相当のスペクトログラム特徴量を作って学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3883af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5-A) dBレンジ自動キャリブレーション（重要）\n",
    "# 目的: 特徴量が0..1で「上側に張り付く（meanが0.8以上）」現象を避けるため、\n",
    "#      STD内のWAVから dB 値の分布をサンプルして MIN_DB/MAX_DB を自動決定します。\n",
    "import numpy as np, librosa, random\n",
    "from pathlib import Path\n",
    "\n",
    "SAMPLE_PER_LABEL = 30  # 各ラベルからサンプルする数（多いほど安定・遅い）\n",
    "P_LOW  = 1.0           # 下側パーセンタイル\n",
    "P_HIGH = 99.0          # 上側パーセンタイル\n",
    "\n",
    "def compute_db_clip_range(std_root: Path):\n",
    "    all_db = []\n",
    "    window = np.hanning(FRAME_LEN).astype(np.float32)\n",
    "\n",
    "    for label in LABELS:\n",
    "        files = list((std_root/label).glob(\"*.wav\"))\n",
    "        if not files:\n",
    "            continue\n",
    "        random.shuffle(files)\n",
    "        files = files[:min(SAMPLE_PER_LABEL, len(files))]\n",
    "        for f in files:\n",
    "            y, _ = librosa.load(str(f), sr=SR, mono=True)\n",
    "            if len(y) < CLIP_SAMPLES:\n",
    "                y = np.pad(y, (0, CLIP_SAMPLES-len(y)))\n",
    "            y = y[:CLIP_SAMPLES]\n",
    "            frames = y.reshape(NUM_FRAMES, FRAME_LEN) * window\n",
    "            fft = np.fft.rfft(frames, n=FFT_SIZE)\n",
    "            mag = np.abs(fft) / FFT_SIZE\n",
    "            mag = mag[:, :FULL_BINS]  # 512\n",
    "            db = 20*np.log10(mag + 1e-12)\n",
    "            all_db.append(db.reshape(-1))\n",
    "    all_db = np.concatenate(all_db, axis=0)\n",
    "    lo = float(np.percentile(all_db, P_LOW))\n",
    "    hi = float(np.percentile(all_db, P_HIGH))\n",
    "    lo -= 5.0\n",
    "    hi += 5.0\n",
    "    return lo, hi\n",
    "\n",
    "MIN_DB, MAX_DB = compute_db_clip_range(STD)\n",
    "print(\"Auto MIN_DB:\", MIN_DB, \"MAX_DB:\", MAX_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c1df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5) tf.data Dataset（BROWSER_FFT特徴量）\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "label_to_id = {l:i for i,l in enumerate(LABELS)}\n",
    "id_to_label = {i:l for l,i in label_to_id.items()}\n",
    "\n",
    "noise_files = [str(p) for p in NOISE_POOL.rglob(\"*.wav\")] if NOISE_POOL.exists() else []\n",
    "print(\"noise_files:\", len(noise_files))\n",
    "\n",
    "MIX_PROB = 0.7  # ノイズ合成を毎回やると unknown に崩壊しやすいので確率で実施\n",
    "\n",
    "\n",
    "def decode_wav(path):\n",
    "    audio = tf.io.read_file(path)\n",
    "    wav, sr = tf.audio.decode_wav(audio, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    n = tf.shape(wav)[0]\n",
    "    wav = tf.cond(n < CLIP_SAMPLES,\n",
    "                  lambda: tf.pad(wav, [[0, CLIP_SAMPLES - n]]),\n",
    "                  lambda: wav[:CLIP_SAMPLES])\n",
    "    return wav\n",
    "\n",
    "def random_mix_noise(wav):\n",
    "    if len(noise_files) == 0:\n",
    "        return wav\n",
    "\n",
    "    # ノイズ合成は確率で実施（毎回合成すると unknown に崩壊しやすい）\n",
    "    if tf.random.uniform([], 0.0, 1.0) >= MIX_PROB:\n",
    "        return wav\n",
    "\n",
    "    nf = tf.random.uniform([], 0, len(noise_files), dtype=tf.int32)\n",
    "    noise = decode_wav(tf.constant(noise_files)[nf])\n",
    "\n",
    "    # SNR を少し高めに（合成しすぎを避ける）\n",
    "    snr_db = tf.random.uniform([], 10.0, 30.0)\n",
    "    wav_rms = tf.sqrt(tf.reduce_mean(tf.square(wav)) + 1e-9)\n",
    "    noi_rms = tf.sqrt(tf.reduce_mean(tf.square(noise)) + 1e-9)\n",
    "\n",
    "    snr = tf.pow(10.0, snr_db / 20.0)\n",
    "    scale = wav_rms / (snr * noi_rms + 1e-9)\n",
    "    mixed = tf.clip_by_value(wav + noise * scale, -1.0, 1.0)\n",
    "    return mixed\n",
    "\n",
    "def wav_to_browserfft_db(wav):\n",
    "    frames = tf.reshape(wav, [NUM_FRAMES, FRAME_LEN])  # [43, 1024]\n",
    "\n",
    "    # WebAudio側に寄せて窓関数を適用（リーケージ低減）\n",
    "    window = tf.signal.hann_window(FRAME_LEN, periodic=True)\n",
    "    frames = frames * window\n",
    "\n",
    "    fft = tf.signal.rfft(frames)                       # [43, 513]\n",
    "    mag = tf.abs(fft)\n",
    "\n",
    "    # ---- 重要：スケーリングをWebAudio寄せ（このままだと上側に飽和しやすい）----\n",
    "    mag = mag / tf.cast(FFT_SIZE, tf.float32)\n",
    "\n",
    "    # Nyquist除外相当で512へ\n",
    "    mag = mag[:, :FULL_BINS]                           # [43, 512]\n",
    "\n",
    "    # dB化\n",
    "    db = 20.0 * (tf.math.log(mag + 1e-12) / tf.math.log(10.0))  # [43, 512]\n",
    "\n",
    "    # 先頭BINSへトリム\n",
    "    db = db[:, :BINS]                                  # [43, BINS]\n",
    "\n",
    "    # クリップして 0..1 正規化\n",
    "    db = tf.clip_by_value(db, MIN_DB, MAX_DB)\n",
    "    db = (db - MIN_DB) / (MAX_DB - MIN_DB)\n",
    "\n",
    "    return db[..., tf.newaxis]                         # [43, BINS, 1]\n",
    "\n",
    "def make_file_label_lists():\n",
    "    paths, labels = [], []\n",
    "    for label in LABELS:\n",
    "        d = STD / label\n",
    "        if not d.exists():\n",
    "            print(\"WARN missing:\", d)\n",
    "            continue\n",
    "        for f in d.glob(\"*.wav\"):\n",
    "            paths.append(str(f))\n",
    "            labels.append(label_to_id[label])\n",
    "    idx = list(range(len(paths)))\n",
    "    random.shuffle(idx)\n",
    "    paths = [paths[i] for i in idx]\n",
    "    labels = [labels[i] for i in idx]\n",
    "    return paths, labels\n",
    "\n",
    "def build_ds(paths, labels, training: bool):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(4096, seed=SEED, reshuffle_each_iteration=True)\n",
    "\n",
    "    def _map(p, y):\n",
    "        wav = decode_wav(p)\n",
    "        if training:\n",
    "            wav = random_mix_noise(wav)\n",
    "        x = wav_to_browserfft_db(wav)\n",
    "        return x, y\n",
    "\n",
    "    ds = ds.map(_map, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(64).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "paths, labels = make_file_label_lists()\n",
    "print(\"total files:\", len(paths))\n",
    "\n",
    "# クラス別split（valに各クラス最低1）\n",
    "from collections import defaultdict\n",
    "by_class = defaultdict(list)\n",
    "for p, y in zip(paths, labels):\n",
    "    by_class[y].append(p)\n",
    "\n",
    "train_paths, val_paths = [], []\n",
    "train_labels, val_labels = [], []\n",
    "val_ratio = 0.15\n",
    "\n",
    "for y, plist in by_class.items():\n",
    "    random.shuffle(plist)\n",
    "    n_val = max(1, int(len(plist) * val_ratio))\n",
    "    val = plist[:n_val]\n",
    "    tr  = plist[n_val:]\n",
    "    val_paths.extend(val);  val_labels.extend([y]*len(val))\n",
    "    train_paths.extend(tr); train_labels.extend([y]*len(tr))\n",
    "\n",
    "train_ds = build_ds(train_paths, train_labels, True)\n",
    "val_ds   = build_ds(val_paths, val_labels, False)\n",
    "\n",
    "# shape check\n",
    "for x,y in train_ds.take(1):\n",
    "    print(\"x:\", x.shape, \"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c329e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5-B) データ分布＆特徴量レンジ確認（任意）\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "print(\"train label counts:\", {LABELS[k]: v for k,v in Counter(train_labels).items()})\n",
    "print(\"val   label counts:\", {LABELS[k]: v for k,v in Counter(val_labels).items()})\n",
    "\n",
    "for xb, yb in train_ds.take(1):\n",
    "    x_np = xb.numpy()\n",
    "    print(\"x batch stats: min\", x_np.min(), \"max\", x_np.max(), \"mean\", x_np.mean(), \"std\", x_np.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843ff260",
   "metadata": {},
   "source": [
    "## 6) モデル（軽量CNN）を学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc6960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6) モデル学習\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "for xb, yb in train_ds.take(1):\n",
    "    input_shape = xb.shape[1:]\n",
    "print(\"input_shape:\", input_shape)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(16, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(len(LABELS), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=15, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5),\n",
    "]\n",
    "\n",
    "# --- クラス重み（頻度の逆数）で unknown への崩壊を防ぐ ---\n",
    "from collections import Counter\n",
    "counts = Counter(train_labels)\n",
    "total = sum(counts.values())\n",
    "class_weight = {}\n",
    "for i, name in enumerate(LABELS):\n",
    "    c = counts.get(i, 1)\n",
    "    class_weight[i] = total / (len(LABELS) * c)\n",
    "\n",
    "# asial は極端に少ないので少しだけブースト（本筋はデータ増）\n",
    "class_weight[label_to_id[CUSTOM_WORD]] *= 5.0\n",
    "\n",
    "print(\"class_weight:\", {LABELS[i]: round(w, 3) for i, w in class_weight.items()})\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6-B) 予測の偏りチェック（任意）\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "pred_hist = Counter()\n",
    "true_hist = Counter()\n",
    "\n",
    "for xb, yb in val_ds:\n",
    "    yp = model.predict(xb, verbose=0)\n",
    "    pred_hist.update(np.argmax(yp, axis=1))\n",
    "    true_hist.update(np.argmax(yb.numpy(), axis=1))\n",
    "\n",
    "print(\"val true hist:\", {LABELS[k]: v for k,v in true_hist.items()})\n",
    "print(\"val pred hist:\", {LABELS[k]: v for k,v in pred_hist.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42507c8",
   "metadata": {},
   "source": [
    "## 7) 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f84b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 7) 評価\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels_idx = list(range(len(LABELS)))\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for xb, yb in val_ds:\n",
    "    yp = model.predict(xb, verbose=0)\n",
    "    y_true.extend(yb.numpy().tolist())\n",
    "    y_pred.extend(np.argmax(yp, axis=1))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_idx)\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=labels_idx,\n",
    "    target_names=LABELS,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafdd7c6",
   "metadata": {},
   "source": [
    "## 8) TFJSへ変換（model.json + metadata.json）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122943bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 8) TFJS 変換＆ metadata.json 生成\n",
    "import tensorflowjs as tfjs\n",
    "import json, shutil, zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "export_dir = WORK / \"tfjs_model\"\n",
    "if export_dir.exists():\n",
    "    shutil.rmtree(export_dir)\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tfjs.converters.save_keras_model(model, str(export_dir))\n",
    "print(\"Saved TFJS model to:\", export_dir)\n",
    "print(\"Files:\", [p.name for p in export_dir.iterdir()])\n",
    "\n",
    "# speech-commands 用 metadata.json\n",
    "metadata = {\n",
    "    \"wordLabels\": LABELS\n",
    "}\n",
    "with open(export_dir / \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 参考：追加情報（任意）\n",
    "extra = {\n",
    "    \"labels\": LABELS,\n",
    "    \"sampleRateHz\": SR,\n",
    "    \"fftSize\": FFT_SIZE,\n",
    "    \"numFrames\": NUM_FRAMES,\n",
    "    \"bins\": BINS\n",
    "}\n",
    "with open(export_dir / \"labels.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(extra, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# zip 化\n",
    "zip_path = WORK / \"tfjs_model.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    for p in export_dir.iterdir():\n",
    "        z.write(p, arcname=p.name)\n",
    "\n",
    "print(\"ZIP:\", zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 9) ZIP をダウンロード\n",
    "from google.colab import files\n",
    "files.download(\"/content/kws/tfjs_model.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1a29a9",
   "metadata": {},
   "source": [
    "## 10) ブラウザ側の読み込み例（BROWSER_FFT）\n",
    "\n",
    "```js\n",
    "recognizer = speechCommands.create(\n",
    "  \"BROWSER_FFT\",\n",
    "  null,\n",
    "  \"/tfjs_model/model.json\",\n",
    "  \"/tfjs_model/metadata.json\"\n",
    ");\n",
    "await recognizer.ensureModelLoaded();\n",
    "```"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
